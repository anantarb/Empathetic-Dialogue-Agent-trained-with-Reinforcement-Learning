{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-training of GPT-2\n",
    "\n",
    "In this notebook we pre-train GPT-2 with the EmpathicDialog dataset to uses as a starting point for bringing in human feedback and to use as a baseline for comparision to our final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "USX1kVz5VdUW"
   },
   "outputs": [],
   "source": [
    "%tensorflow_version 1.13.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect your own google drive to this notebook for saving the trained models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uEmQ8U4CWnA-"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "APqQ_rCNZWxd"
   },
   "outputs": [],
   "source": [
    "%cd /content/drive/My Drive/nlp-2021-vda\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the initial GPT-2 Model from Google Cloud storage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "injQs43LULmP"
   },
   "outputs": [],
   "source": [
    "# Uncomment the line below if you are running the notebook for the first time\n",
    "\n",
    "#!gsutil -m cp -r gs://nlp-lab/* ./\n",
    "\n",
    "# For local run on mac (not in google colab)\n",
    "#!gsutil -m cp -r 'gs://nlp-lab/*' ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L6XTMyY8aEb9"
   },
   "outputs": [],
   "source": [
    "from scripts import pre_train_gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x-lJ5GmIa8L_"
   },
   "outputs": [],
   "source": [
    "sess = pre_train_gpt2.start_tf_sess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nlttl3BmWH8e"
   },
   "outputs": [],
   "source": [
    "#Parameters Descriptions\n",
    "\n",
    "# sess - Tensorflow session\n",
    "# dataset - path where the data is located\n",
    "# steps - for how many steps do you wanna train the model\n",
    "# model_name - Initial GPT model name i.e 124M or 335M or 775M\n",
    "# model_dir - path where the initial GPT model is stored\n",
    "# batch_size - Batch Size\n",
    "# learning_rate - Learning Rate\n",
    "# accumulate gradients - Accumulate gradients across N minibatches\n",
    "# input_maxlen - maximum length of input tokens\n",
    "# history_len - How many previous dialogues should be used in the context\n",
    "# restore_from - Either \"latest\", \"fresh\", or a path to a checkpoint file\n",
    "# run_name - Run id. Name of subdirectory in checkpoint/\n",
    "# checkpoint_dir - path where the checkpoints should be stored or located\n",
    "# multi_gpu - set True, if you have multiple GPUs\n",
    "# save_every - Write a checkpoint every N steps\n",
    "# print_every - Print stats every N steps\n",
    "# optimizer - which optimizer to use\n",
    "# overwrite - Set true, if you wanna overwrite previous checkpoints\n",
    "\n",
    "pre_train_gpt2.finetune(sess,\n",
    "             'datasets/empatheticdialogues/train.csv',\n",
    "             'datasets/empatheticdialogues/valid.csv',\n",
    "             steps=-1,\n",
    "             model_name='124M',\n",
    "             model_dir='gpt-2/models',\n",
    "             batch_size=20,\n",
    "             learning_rate=0.0001,\n",
    "             accumulate_gradients=5,\n",
    "             input_maxlen=100,\n",
    "             history_len=4,\n",
    "             patience=20,\n",
    "             restore_from='latest',\n",
    "             run_name='run1',\n",
    "             checkpoint_dir='checkpoint',\n",
    "             multi_gpu=False,\n",
    "             print_every=1,\n",
    "             max_checkpoints=1,\n",
    "             optimizer='adam',\n",
    "             overwrite=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyODDvRIwzT0zCovDxT8du1X",
   "collapsed_sections": [],
   "mount_file_id": "1uNIL-AdQwXcskmmRrHUgpNiUw3chOsyX",
   "name": "train_notebook.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
