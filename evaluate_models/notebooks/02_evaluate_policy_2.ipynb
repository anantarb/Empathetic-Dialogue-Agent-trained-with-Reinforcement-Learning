{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"02_evaluate_policy_2.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"}},"cells":[{"cell_type":"markdown","metadata":{"id":"eHPO1tlfqSNA"},"source":["To run this notebook you need a folder called 'data' at your current location that includes the files '', '', '' and '' from the git repository at 'evaluate_models/data'. Furthermore you need everything from the git repo at 'evaluate_models/empathy_mental_health' in a folder called 'empathy_mental_health' at your current location."]},{"cell_type":"code","metadata":{"id":"vQdBrq375zK8"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YKsQh-AH6BYE"},"source":["%cd /content/drive/MyDrive/nlp-2021-vda/evaluate_models/\n","!pwd"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j-7fVjPSR4pF"},"source":["If you want to run evaluation on our sampled responses, download data from google cloud storage."]},{"cell_type":"code","metadata":{"id":"tjeVxxsNR8Xb"},"source":["import os\n","if not os.path.isdir('./sampled_responses'):\n","    !gsutil -m cp -r gs://nlp-lab/evaluate_models/sampled_responses ./"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9d1j3iTvoTlI"},"source":["if not os.path.isdir('./empathy_mental_health/trained_models'):\n","  !gsutil -m cp -r gs://nlp-lab/evaluate_models/empathy_mental_health/trained_models ./empathy_mental_health/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ppaOrkXA6GDn"},"source":["!pip install -U nltk"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cqcy6MLUcVsh"},"source":["!pip install transformers"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lCcgPde6QTsH"},"source":["When nltk.download opens choose 'Download' and as package 'stopwords'. Then \n","choose quit."]},{"cell_type":"code","metadata":{"id":"OWEKEXCo6IsU"},"source":["import json\n","import nltk\n","nltk.download()\n","from nltk.translate.meteor_score import meteor_score\n","import matplotlib.pyplot as plt\n","import numpy as np\n","nltk.download('wordnet')\n","\n","# Metric calculation \n","from data import metrics\n","from data import parse_sampled_responses\n","from data import metric_averages_or_ratios\n","\n","# For plotting\n","import plotly.express as px\n","import plotly.graph_objs as go\n","import pandas as pd\n","from plotly.subplots import make_subplots\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GyVFRYloHR60"},"source":["# METEOR"]},{"cell_type":"markdown","metadata":{"id":"SLiFfm5GSCBK"},"source":["Plot METEOR Score vs Training Step and Returns vs Training Step"]},{"cell_type":"code","metadata":{"id":"7mX4CpJu6K3M"},"source":["path_list = ['supervised_0.7', 'run6_1', 'run6_2', 'run6_3', 'run6_4', 'run6_5', 'run6_6', 'run6_7', 'run6_8']\n","file_scores = []\n","gold_path = 'sampled_responses/policy-2/gold.json'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3k4XTcUZ6gDi"},"source":["for path in path_list:\n","  with open(gold_path) as f:\n","    gold = json.load(f)\n","\n","  with open(f\"sampled_responses/policy-2/{path}.json\") as f:\n","    data = json.load(f)\n","  scores = []\n","  for i in range(len(gold)):\n","    score = meteor_score([gold[i]['gold_response']], data[i]['sample0'])\n","    scores.append(score)\n","  file_scores.append(sum(scores) / len(scores))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kwcwit-mbmAJ"},"source":["x = [0, 25, 50, 75, 100, 125, 150, 175, 200]\n","returns = [0.82, 0.92, 2.56, 1.97, 2.84, 2.21, 2.41, 1.94, -0.11]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FZDJPgAG6-sW"},"source":["fig, ax1 = plt.subplots()\n","\n","color = 'tab:blue'\n","ax1.set_xlabel('Training step')\n","ax1.set_ylabel('METEOR score', color=color)\n","ax1.plot(x, file_scores, color=color)\n","ax1.tick_params(axis='y', labelcolor=color)\n","\n","ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n","\n","color = 'tab:orange'\n","ax2.set_ylabel('Returns', color=color)  # we already handled the x-label with ax1\n","ax2.plot(x, returns, color=color)\n","ax2.tick_params(axis='y', labelcolor=color)\n","\n","fig.tight_layout()  # otherwise the right y-label is slightly clipped\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZiWBxQbOSEvq"},"source":["Calculate METEOR score of training_step=75 model for different values of temperature"]},{"cell_type":"code","metadata":{"id":"0nvf0ckIBcdk"},"source":["path_list = ['run6_3', 'run6_3_0.5t', 'run6_3_0t']\n","file_scores = []\n","gold_path = 'sampled_responses/policy-2/gold.json'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dervK6tQCCR9"},"source":["for path in path_list:\n","  with open(gold_path) as f:\n","    gold = json.load(f)\n","\n","  with open(f\"sampled_responses/policy-2/{path}.json\") as f:\n","    data = json.load(f)\n","  scores = []\n","  for i in range(len(gold)):\n","    score = meteor_score([gold[i]['gold_response']], data[i]['sample0'])\n","    scores.append(score)\n","  file_scores.append(sum(scores) / len(scores))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dhyhwSx5CEdA"},"source":["print(\"Training Step            Temperature                METEOR Score\")\n","print(\"75                      \", 0.7, \"                   \",file_scores[0])\n","print(\"75                      \", 0.5, \"                   \",file_scores[1])\n","print(\"75                      \", 0, \"                     \",file_scores[2])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2t2KpYg5HR63"},"source":["# Perplexity"]},{"cell_type":"markdown","metadata":{"id":"APy5UXeXHR63"},"source":["# Utterance length"]},{"cell_type":"code","metadata":{"id":"EZKuYxSfHR63"},"source":["path_list = ['supervised_0.7', 'run6_1', 'run6_2', 'run6_3', 'run6_4', 'run6_5', 'run6_6', 'run6_7', 'run6_8']\n","x = [0, 25, 50, 75, 100, 125, 150, 175, 200]\n","gold_path = 'sampled_responses/policy-2/gold.json'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Sbw00MrBHR63"},"source":["def getWordCountMetricDictFromFilename(file_name, metric_dict):\n","    parsed_conversations = parse_sampled_responses.getParsedConversations(f\"sampled_responses/policy-2/{file_name}.json\",'sample0')\n","\n","    parsed_conversations_dict = metric_averages_or_ratios.getMetricDict(parsed_conversations,metric_dict,metric_dict)\n","    return parsed_conversations_dict\n","\n","def getGoldMetricDict(metric_dict):\n","    parsed_gold_conversations = parse_sampled_responses.getParsedConversations(gold_path,'gold_response')\n","    gold_metric = metric_averages_or_ratios.getMetricDict(parsed_gold_conversations,metric_dict,metric_dict)\n","    return gold_metric\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yxQEp8h2HR64"},"source":["utterance_length_dict = {}\n","utterance_length_metric_names = ['utterance_length']\n","\n","gold_utterance_length = getGoldMetricDict(utterance_length_metric_names)\n","\n","counter = 0\n","for path in path_list:\n","    utterance_length = getWordCountMetricDictFromFilename(path,utterance_length_metric_names)\n","    utterance_length_dict[x[counter]] = utterance_length['utterance_length']\n","    counter = counter + 1\n","    \n","print(utterance_length_dict)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xh6hSsSIHR64"},"source":["fig = px.line(x=list(utterance_length_dict.keys()), y=list(utterance_length_dict.values()), title='Utternace length')\n","fig.add_shape(go.layout.Shape(type=\"line\",\n","                                    name=\"gold\",\n","                                    x0=0,\n","                                    y0=gold_utterance_length['utterance_length'],\n","                                    x1=200,\n","                                    y1=gold_utterance_length['utterance_length'],\n","                                    line=dict(color='yellow', width=2),))\n","fig.append_trace(go.Scatter(\n","        showlegend = False,\n","        x=[210],\n","        y=[gold_utterance_length['utterance_length']],\n","        text=[\"gold\"],\n","        mode=\"text\",\n","    ),row=1,col=1)\n","fig.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iQReYgDfHR64"},"source":["# Repetition"]},{"cell_type":"code","metadata":{"id":"uuYlWwmVHR64"},"source":["repetition_dict = {}\n","\n","repetition_metric_names = ['conversation_repetition',\n","                            'self_repetition',\n","                            'utterance_repetition',\n","                            'word_repetition']\n","\n","gold_repetition_dict = getGoldMetricDict(repetition_metric_names)\n","\n","\n","counter = 0\n","for path in path_list:\n","    repetition_metrics = getWordCountMetricDictFromFilename(path,repetition_metric_names)\n","    repetition_dict[x[counter]] = repetition_metrics\n","    counter = counter + 1\n","print(repetition_dict)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"65ZDd12IHR65"},"source":["nrows = 4\n","df = pd.DataFrame(repetition_dict).transpose()\n","\n","plot_names = [i[0] for i in list(gold_repetition_dict.items())]\n","\n","fig = make_subplots(rows=nrows, cols=1, subplot_titles=plot_names)\n","\n","fig.update_xaxes(title_text=\"KL\", row=nrows, col=1)\n","fig.update_yaxes(title_text=\"average word count\", row=2, col=1)\n","\n","\n","for i in range(0,nrows):\n","    fig.append_trace(go.Scatter(\n","        x=list(df.index),\n","        y=df.iloc[:,i],\n","        name=plot_names[i],\n","        legendgroup = '1',\n","    ), row=(i+1), col=1)\n","\n","\n","# add shapes\n","col_count = 1\n","for i in range(0,nrows):\n","    gold = list(gold_repetition_dict.items())[i][1]\n","    fig.add_shape(go.layout.Shape(type=\"line\",\n","                                    name=\"gold\",\n","                                    x0=0,\n","                                    y0=gold,\n","                                    x1=200,\n","                                    y1=gold,\n","                                    line=dict(color='yellow', width=2),),\n","                  row=(i+1),\n","                  col=1)\n","    fig.append_trace(go.Scatter(\n","        showlegend = False,\n","        x=[210],\n","        y=[gold],\n","        text=[\"gold\"],\n","        mode=\"text\",\n","    ), row=(i+1), col=1)\n","    col_count = col_count+1\n","\n","\n","fig.update_layout(height=600, width=800, title_text=\"Word Count metrics vs number of training steps\")\n","fig.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LZmbvVJqHR66"},"source":["# Question"]},{"cell_type":"code","metadata":{"id":"MZ89Yk26HR66"},"source":["def getQuestionMetricDictFromFile(data_filepath,gold_filepath,response_type):\n","    parsed_conversations = parse_sampled_responses.getParsedConversations(data_filepath,response_type)\n","\n","    parsed_conversations_dict = metric_averages_or_ratios.getMetricDict(parsed_conversations,['question'], ['question'])\n","    \n","    if response_type == 'gold_response':\n","        parsed_conversations_dict[\"ratio_of_sample_is_question_of_all_samples\"] = 0\n","        parsed_conversations_dict[\"ratio_of_sample_is_question_if_gold_is_question\"] = 0\n","        parsed_conversations_dict[\"ratio_of_sample_is_question_if_gold_is_no_question\"] = 0\n","    else:\n","        parsed_conversations_gold = parse_sampled_responses.getParsedConversations(gold_filepath,'gold_response')\n","        parsed_conversations_dict[\"ratio_of_sample_is_question_of_all_samples\"] = metric_averages_or_ratios.getSampleQuestionOfAllSamplesRatio(parsed_conversations)\n","        parsed_conversations_dict[\"ratio_of_sample_is_question_if_gold_is_question\"] = metric_averages_or_ratios.getGoldQuestionVsSampleRatio(parsed_conversations_gold,parsed_conversations)\n","        parsed_conversations_dict[\"ratio_of_sample_is_question_if_gold_is_no_question\"] = metric_averages_or_ratios.getNoGoldQuestionVsSampleRatio(parsed_conversations_gold,parsed_conversations)\n","    \n","    return parsed_conversations_dict"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9SPK8Q5FHR66"},"source":["question_dict = {}\n","\n","gold_question_dict = getQuestionMetricDictFromFile(gold_path,gold_path,'gold_response')\n","\n","\n","counter = 0\n","for path in path_list:\n","    print(path)\n","    question_metrics = getQuestionMetricDictFromFile(f\"sampled_responses/policy-2/{path}.json\",gold_path,'sample0')\n","    question_dict[x[counter]] = question_metrics\n","    counter = counter + 1\n","print(question_dict)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oMwOWc9oHR67"},"source":["nrows = 4\n","\n","df = pd.DataFrame(question_dict).transpose()\n","\n","plot_names = [i[0] for i in list(gold_question_dict.items())]\n","\n","fig = make_subplots(rows=nrows, cols=1, subplot_titles=plot_names)\n","\n","fig.update_xaxes(title_text=\"Training steps\", row=nrows, col=1)\n","fig.update_yaxes(title_text=\"value\", row=(2), col=1)\n","\n","\n","for i in range(0,nrows):\n","    fig.append_trace(go.Scatter(\n","        x=list(df.index),\n","        y=df.iloc[:,i],\n","        name=plot_names[i],\n","        legendgroup = '1',\n","    ), row=(i+1), col=1)\n","\n","\n","# add shapes\n","    \n","gold = list(gold_question_dict.items())[0][1]\n","fig.add_shape(go.layout.Shape(type=\"line\",\n","                                    name=\"gold\",\n","                                    x0=0,\n","                                    y0=gold,\n","                                    x1=200,\n","                                    y1=gold,\n","                                    line=dict(color='yellow', width=2),),\n","                  row=(1),\n","                  col=1)\n","fig.append_trace(go.Scatter(\n","    showlegend = False,\n","    x=[210],\n","    y=[gold],\n","    text=[\"gold\"],\n","    mode=\"text\",\n","), row=1, col=1)\n","\n","\n","fig.update_layout(height=600, width=1000, title_text=\"Word Count metrics vs number of training steps\")\n","fig.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kaUPtCBOHR67"},"source":["# Empathy"]},{"cell_type":"code","metadata":{"id":"px2wZUXJHR68"},"source":["content_metric_names = ['empathy']\n","\n","content_metric_names_separated = [\n","                            'emotional_reaction_level',\n","                            'interpretation_level',\n","                            'exploration_level']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"o8X5NjTcHR68"},"source":["MAX_SAMPLE = 100"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8lhdZnpiHR68"},"source":["def getContentMetricDictFromFile(data_filepath,gold_filepath,response_type):\n","    print(\"start\")\n","    parsed_conversations = parse_sampled_responses.getParsedConversations(data_filepath,response_type)[0:MAX_SAMPLE]\n","\n","    parsed_conversations_dict = metric_averages_or_ratios.getMetricDict(parsed_conversations,content_metric_names, content_metric_names_separated)\n","    \n","    return parsed_conversations_dict"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9JqhMjWxHR68"},"source":["gold_content_metrics = getContentMetricDictFromFile(gold_path,gold_path,'gold_response')\n","\n","empathy_dict = {}\n","counter = 0\n","for path in path_list:\n","    print(path)\n","    empathy_metrics = getContentMetricDictFromFile(f\"sampled_responses/policy-2/{path}.json\",gold_path,'sample0')\n","    empathy_dict[x[counter]] = empathy_metrics\n","    counter = counter + 1\n","print(empathy_dict)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hes6K7A4HR69"},"source":["df2 = pd.DataFrame(empathy_dict).transpose()\n","\n","nrows = 3\n","\n","plot_names = [i[0] for i in list(gold_content_metrics.items())]\n","\n","fig = make_subplots(rows=nrows, cols=1, subplot_titles=plot_names)\n","\n","for i in range(0,nrows):\n","    fig.append_trace(go.Scatter(\n","        x=list(df2.index),\n","        y=df2.iloc[:,i],\n","        name=plot_names[i],\n","        legendgroup = '1',\n","    ), row=(i+1), col=1)\n","    \n","fig.update_xaxes(title_text=\"training steps\", row=nrows, col=1)\n","fig.update_yaxes(title_text=\"average word count\", row=(2), col=1)\n","\n","\n","# add shapes\n","col_count = 1\n","for i in range(0,nrows):\n","    gold = list(gold_content_metrics.items())[i][1]\n","    fig.add_shape(go.layout.Shape(type=\"line\",\n","                                    x0=0,\n","                                    y0=gold,\n","                                    x1=200,\n","                                    y1=gold,\n","                                    line=dict(color='yellow', width=2),),\n","                  row=(i+1),\n","                  col=1)\n","    fig.append_trace(go.Scatter(\n","        showlegend = False,\n","        x=[210],\n","        y=[gold],\n","        text=[\"gold\"],\n","        mode=\"text\",\n","    ), row=(i+1), col=1)\n","    col_count = col_count+1\n","\n","\n","fig.update_layout(height=600, width=800, title_text=\"Word Count metrics vs KL calculated from \"+str(MAX_SAMPLE)+\" samples\")\n","fig.show()"],"execution_count":null,"outputs":[]}]}