{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"01_distribute_data.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN5mQ8tToaXxNM5pP0BUYnd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"FBV53H8LiH4k"},"source":["%tensorflow_version 1.13.1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bQGSyiDTiQZS"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HMicD7swiW0q"},"source":["%cd /content/drive/My Drive/nlp-2021-vda/annotate_data\n","!pwd"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lsEPSgw0kFHD"},"source":["If you want to distribute our sampled data, download the data from google cloud."]},{"cell_type":"code","metadata":{"id":"1nuM2IR1kRIL"},"source":["import os\n","if not os.path.isdir('./datasets'):\n","    os.mkdir('./datasets')\n","if not os.path.isdir('./datasets/sampled_responses'):\n","    !gsutil -m cp -r gs://nlp-lab/annotate_data/datasets/sampled_responses ./datasets/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wVCZwsreiZCJ"},"source":["from data.distribute_data import distribute_data, decode_distributed_data\n","from models import encodings\n","import json"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"46pDDeBPim5S"},"source":["# data_path- path where sampled responses are located\n","# annotators - pass annotators names in the list\n","# same_data - how many data should be same in each annotators quota to computer statistics later\n","# total_for_each - how much data should be placed in each annotators quota\n","# seed - set seed if you want to reproduce data\n","\n","annotators = [\"ananta\", \"vivi\", \"sophie\", \"monika\"]\n","data_path = \"datasets/sampled_responses/355M_supervised_0.7t.json\"\n","distributed_data = distribute_data(data_path, annotators, same_data=100, total_for_each=2000, seed=245)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X4pPN3AwiqbR"},"source":["checkpoint_path = 'gpt-2/models/124M'\n","enc = encodings.Encoding(\"main\", n_vocab=50257, eot_token=50256, base_path=checkpoint_path).get_encoder()\n","distributed_decoded_data = decode_distributed_data(distributed_data, enc)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qa2tSOGyjBn0"},"source":["# write data into the file\n","if not os.path.isdir('./datasets/distributed_data'):\n","    os.mkdir('./datasets/distributed_data')\n","with open('datasets/distributed_data/distributed_data.json', 'w') as f:\n","    json.dump(distributed_data, f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"euTwAV6Gj70y"},"source":["# write data into the file\n","with open('datasets/distributed_data/decoded_distributed_data.json', 'w') as f:\n","    json.dump(distributed_decoded_data, f)"],"execution_count":null,"outputs":[]}]}